{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: CoNLL Format Dataset Labeling\n",
    "Creating labeled dataset for NER training with BIO tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "from preprocessing.conll_labeler import CoNLLLabeler\n",
    "from preprocessing.text_preprocessor import AmharicTextPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5800 processed messages\n"
     ]
    }
   ],
   "source": [
    "# Load processed data from Task 1\n",
    "processed_df = pd.read_csv(\"../data/processed/processed_telegram_data.csv\")\n",
    "print(f\"Loaded {len(processed_df)} processed messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor and labeler initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize preprocessor and labeler\n",
    "preprocessor = AmharicTextPreprocessor()\n",
    "labeler = CoNLLLabeler()\n",
    "print(\"Preprocessor and labeler initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 5800 messages for labeling\n",
      "Sample messages:\n",
      "1. 4 1 304 500 ዋጋ፦ ብር ውስን ፍሬ ነው ያለው መገናኛ መሰረት ደፋር ሞል ሁለተኛ ፎቅ ቢሮ ቁ 05 06 0902660722 ...\n",
      "2. 6 የጫማ ማስቀመጫ ባለ ስድስት ደረጃ ቦታ ቆጣቢ ሲዘረጋ 27 27 86 ስፋት ከጠንካራ ፕላስቲክ የተሰራ ገጠማ የማይፈልግ 6 ጥ...\n",
      "3. 6 የጫማ ማስቀመጫ ባለ ስድስት ደረጃ ቦታ ቆጣቢ ሲዘረጋ 27 27 86 ስፋት ከጠንካራ ፕላስቲክ የተሰራ ገጠማ የማይፈልግ 6 ጥ...\n"
     ]
    }
   ],
   "source": [
    "# Prepare sample for labeling (50 messages)\n",
    "# sample_df = preprocessor.prepare_for_labeling(processed_df, sample_size=50)\n",
    "sample_df = processed_df[['id', 'channel', 'text', 'tokens']]\n",
    "print(f\"Selected {len(sample_df)} messages for labeling\")\n",
    "print(\"Sample messages:\")\n",
    "for i, text in enumerate(sample_df['text'].head(3)):\n",
    "    print(f\"{i+1}. {text[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created labeled dataset with 50 sentences\n"
     ]
    }
   ],
   "source": [
    "# Create labeled dataset\n",
    "messages = sample_df['text'].tolist()\n",
    "labeled_data = labeler.create_extended_dataset(messages, target_size=50)\n",
    "print(f\"Created labeled dataset with {len(labeled_data)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Labeled Data (CoNLL Format):\n",
      "\n",
      "Sample 1: ሰላም! የሕፃናት ጠርሙስ ዋጋ 150 ብር ነው። ቦሌ አካባቢ ነው።...\n",
      "Tokens and Labels:\n",
      "  ሰላም             O\n",
      "  !               O\n",
      "  የሕፃናት           B-Product\n",
      "  ጠርሙስ            I-Product\n",
      "  ዋጋ              B-PRICE\n",
      "  150             B-PRICE\n",
      "  ብር              I-PRICE\n",
      "  ነው።             O\n",
      "  ቦሌ              B-LOC\n",
      "  አካባቢ            O\n",
      "  ... (1 more tokens)\n",
      "\n",
      "Sample 2: አዲስ አበባ ውስጥ የሚሸጥ ልብስ በ 200 ብር...\n",
      "Tokens and Labels:\n",
      "  አዲስ             B-LOC\n",
      "  አበባ             I-LOC\n",
      "  ውስጥ             O\n",
      "  የሚሸጥ            O\n",
      "  ልብስ             B-Product\n",
      "  በ               B-PRICE\n",
      "  200             B-PRICE\n",
      "  ብር              I-PRICE\n",
      "\n",
      "Sample 3: መርካቶ ውስጥ ጫማ 300 ብር...\n",
      "Tokens and Labels:\n",
      "  መርካቶ            B-LOC\n",
      "  ውስጥ             O\n",
      "  ጫማ              B-Product\n",
      "  300             B-PRICE\n",
      "  ብር              I-PRICE\n"
     ]
    }
   ],
   "source": [
    "# Display sample labeled data\n",
    "print(\"Sample Labeled Data (CoNLL Format):\")\n",
    "for i, (message, tokens, labels) in enumerate(labeled_data[:3]):\n",
    "    print(f\"\\nSample {i+1}: {message[:60]}...\")\n",
    "    print(\"Tokens and Labels:\")\n",
    "    for token, label in zip(tokens[:10], labels[:10]):\n",
    "        print(f\"  {token:<15} {label}\")\n",
    "    if len(tokens) > 10:\n",
    "        print(f\"  ... ({len(tokens)-10} more tokens)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Statistics:\n",
      "  Product: 17 mentions\n",
      "  PRICE: 100 mentions\n",
      "  LOC: 14 mentions\n",
      "  Total entities: 131\n",
      "  O (non-entity) labels: 1528\n"
     ]
    }
   ],
   "source": [
    "# Entity statistics\n",
    "all_labels = [label for _, _, labels in labeled_data for label in labels]\n",
    "entity_counts = {}\n",
    "for label in all_labels:\n",
    "    if label != 'O':\n",
    "        entity_type = label.split('-')[1] if '-' in label else label\n",
    "        entity_counts[entity_type] = entity_counts.get(entity_type, 0) + 1\n",
    "\n",
    "print(\"Entity Statistics:\")\n",
    "for entity_type, count in entity_counts.items():\n",
    "    print(f\"  {entity_type}: {count} mentions\")\n",
    "print(f\"  Total entities: {sum(entity_counts.values())}\")\n",
    "print(f\"  O (non-entity) labels: {all_labels.count('O')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIO Validation Results:\n",
      "  Valid sequences: 50/50\n",
      "  Validation rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Validate BIO tagging consistency\n",
    "valid_count = 0\n",
    "for message, tokens, labels in labeled_data:\n",
    "    if labeler.validate_labels(tokens, labels):\n",
    "        valid_count += 1\n",
    "\n",
    "print(f\"BIO Validation Results:\")\n",
    "print(f\"  Valid sequences: {valid_count}/{len(labeled_data)}\")\n",
    "print(f\"  Validation rate: {valid_count/len(labeled_data)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-21 18:45:48.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.conll_labeler\u001b[0m:\u001b[36msave_conll_format\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1mCoNLL format data saved to ../data/labeled/ethiopian_ner_dataset.txt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoNLL dataset saved to: ../data/labeled/ethiopian_ner_dataset.txt\n"
     ]
    }
   ],
   "source": [
    "# Save in CoNLL format\n",
    "conll_path = \"../data/labeled/ethiopian_ner_dataset.txt\"\n",
    "labeler.save_conll_format(labeled_data, conll_path)\n",
    "print(f\"CoNLL dataset saved to: {conll_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-21 18:45:49.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.conll_labeler\u001b[0m:\u001b[36mload_conll_format\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mLoaded 50 sentences from ../data/labeled/ethiopian_ner_dataset.txt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification: Loaded 50 sentences from saved file\n",
      "Dataset ready for NER model training!\n"
     ]
    }
   ],
   "source": [
    "# Verify saved data by loading it back\n",
    "loaded_data = labeler.load_conll_format(conll_path)\n",
    "print(f\"Verification: Loaded {len(loaded_data)} sentences from saved file\")\n",
    "print(\"Dataset ready for NER model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
