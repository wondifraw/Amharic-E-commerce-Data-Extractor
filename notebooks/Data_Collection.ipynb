{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üï∑Ô∏è Telegram Data Collection\n",
    "\n",
    "## Overview\n",
    "Automated data collection from Telegram e-commerce channels:\n",
    "- Multi-channel scraping\n",
    "- Media download and storage\n",
    "- Rate limiting and caching\n",
    "- CSV export with metadata\n",
    "\n",
    "**Output**: `../data/telegram_data.csv`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from data_collection.telegram_scraper import TelegramScraper, ScrapingConfig\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Channels to scrape: 5\n",
      "üíæ Output file: ../data/telegram_data.csv\n",
      "‚úÖ Configuration loaded\n"
     ]
    }
   ],
   "source": [
    "# Telegram channels to scrape\n",
    "CHANNELS = [\n",
    "    '@classybrands',\n",
    "    '@Shageronlinestore', \n",
    "    '@ZemenExpress',\n",
    "    '@sinayelj',\n",
    "    '@modernshoppingcenter'\n",
    "]\n",
    "\n",
    "# Get credentials\n",
    "API_ID = os.getenv('TG_API_ID')\n",
    "API_HASH = os.getenv('TG_API_HASH')\n",
    "OUTPUT_FILE = '../data/telegram_data.csv'\n",
    "\n",
    "if not API_ID or not API_HASH:\n",
    "    print(\"‚ö†Ô∏è API credentials not found in .env file\")\n",
    "    API_ID = input(\"Enter your Telegram API ID: \")\n",
    "    API_HASH = input(\"Enter your Telegram API Hash: \")\n",
    "\n",
    "print(f\"üì° Channels to scrape: {len(CHANNELS)}\")\n",
    "print(f\"üíæ Output file: {OUTPUT_FILE}\")\n",
    "print(\"‚úÖ Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Start Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scraper configuration\n",
    "scraper_config = ScrapingConfig(\n",
    "    api_id=API_ID,\n",
    "    api_hash=API_HASH,\n",
    "    output_file=OUTPUT_FILE,\n",
    "    max_messages=5000\n",
    ")\n",
    "\n",
    "# Initialize scraper with config object\n",
    "scraper = TelegramScraper(scraper_config)\n",
    "\n",
    "print(\"üîÑ Starting data collection...\")\n",
    "print(f\"‚è∞ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Run scraping\n",
    "results = await scraper.scrape_channels(CHANNELS)\n",
    "\n",
    "print(f\"‚úÖ Collection completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"üìä Results:\")\n",
    "for channel, count in results.items():\n",
    "    print(f\"  {channel}: {count} messages\")\n",
    "\n",
    "await scraper.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display data summary\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    df = pd.read_csv(OUTPUT_FILE)\n",
    "    \n",
    "    print(\"üìà Collection Summary:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Total messages: {len(df):,}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "    \n",
    "    # Messages per channel\n",
    "    channel_counts = df['Channel Username'].value_counts()\n",
    "    print(\"\\nüì° Messages per channel:\")\n",
    "    for channel, count in channel_counts.items():\n",
    "        print(f\"  {channel}: {count:,} messages\")\n",
    "    \n",
    "    print(\"\\nüëÄ Sample data:\")\n",
    "    print(df.head(3)[['Channel Username', 'Message', 'Date']].to_string())\n",
    "else:\n",
    "    print(\"‚ùå No data file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Collection Complete\n",
    "\n",
    "**Next Steps:**\n",
    "1. Run `Preprocessing.ipynb` to clean and label the data\n",
    "2. Train NER models using the fine-tuning notebooks\n",
    "3. Generate vendor analytics with `vendor_scorecard_Engine.ipynb`\n",
    "\n",
    "**Files Created:**\n",
    "- Raw scraped data in configured output path\n",
    "- Media files (if enabled)\n",
    "- Cache files for incremental updates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
